{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = 400000\n",
    "embedding_dim = 50\n",
    "hidden_layer_size = 80\n",
    "num_rows = 1000\n",
    "num_steps = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_glove(filename):\n",
    "    file = open(filename)    \n",
    "    embedding = np.ndarray([vocab_size, embedding_dim])\n",
    "    word_id_dict = {}\n",
    "    id = 0\n",
    "    for line in file:\n",
    "        items = line.split(' ')\n",
    "        word_id_dict[items[0]] = id\n",
    "        embedding[id,:] = np.array([float(i) for i in items[1:]])\n",
    "        id += 1\n",
    "    file.close()\n",
    "    return(embedding, word_id_dict)\n",
    "\n",
    "embedding, word_id_dict = read_glove(\"../../datasets/glove.6B/glove.6B.50d.txt\")\n",
    "\n",
    "def read_data(filename):\n",
    "    file = open(filename)\n",
    "    chapter_input = []\n",
    "    data = []\n",
    "    for line in file:\n",
    "        items = re.sub('[?.]', '', line).lower().split()\n",
    "        if items[0] == '1':\n",
    "            chapter_input = items[1:] + ['.']\n",
    "        elif items[-1].isdigit():\n",
    "            data.append({'I': chapter_input,\n",
    "                         'Q': items[1:-2],\n",
    "                         'A': [items[-2]]})\n",
    "        else:\n",
    "            chapter_input = chapter_input + items[1:] + ['.']\n",
    "    file.close()\n",
    "    return(data)\n",
    "\n",
    "def max_len(data, iqa):\n",
    "    max_len = 0\n",
    "    for i in data:\n",
    "        max_len = max(max_len, len(i[iqa]))\n",
    "    return(max_len)\n",
    "\n",
    "def embed_and_pad(data):\n",
    "    inputs = np.zeros([len(data), max_len(data, 'I'), embedding_dim])\n",
    "    questions = np.zeros([len(data), max_len(data, 'Q'), embedding_dim])\n",
    "    for index, row in enumerate(data):\n",
    "        inputs[index,0:len(row['I']),:] = embedding[[word_id_dict[token] for token in row['I']]]\n",
    "        questions[index,0:len(row['Q']),:] = embedding[[word_id_dict[token] for token in row['Q']]]\n",
    "    return((inputs, questions))\n",
    "\n",
    "def get_answer_index(data):\n",
    "    answers = np.zeros(num_rows)\n",
    "    for index, row in enumerate(data):\n",
    "        answers[index] = word_id_dict[row['A'][0]]\n",
    "    return(answers)\n",
    "\n",
    "def get_input_sequence_lengths(data):\n",
    "    input_sequence_lengths = []\n",
    "    for i in data:\n",
    "        input_sequence_lengths.append(len(i['I']))\n",
    "    return(input_sequence_lengths)\n",
    "\n",
    "def get_input_period_boolean(data):\n",
    "    input_period_boolean = np.zeros((num_rows, max_input_len), dtype=bool)\n",
    "    for index, row in enumerate(data):\n",
    "        input_period_boolean[index, [i for i, j in enumerate(row['I']) if j=='.']] = True\n",
    "    return(input_period_boolean)\n",
    "\n",
    "def get_max_facts(input_period_boolean):\n",
    "    max_facts = max([sum(i) for i in input_period_boolean])\n",
    "    return(max_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = read_data(\"../../datasets/facebook_babi/tasks_1-20_v1-2/en/qa1_single-supporting-fact_train.txt\")\n",
    "max_input_len = max_len(data, 'I')\n",
    "max_question_len = max_len(data, 'Q')\n",
    "max_answer_len = max_len(data, 'A')\n",
    "data_inputs, data_questions = embed_and_pad(data)\n",
    "data_answers = get_answer_index(data)\n",
    "input_sequence_lengths = get_input_sequence_lengths(data)\n",
    "input_period_boolean = get_input_period_boolean(data)\n",
    "max_facts = get_max_facts(input_period_boolean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Placeholders\n",
    "inputs = tf.placeholder(tf.float32, shape=[num_rows, max_input_len, embedding_dim])\n",
    "questions = tf.placeholder(tf.float32, shape=[num_rows, max_question_len, embedding_dim])\n",
    "answers = tf.placeholder(tf.int32, shape=[num_rows])\n",
    "periods = tf.placeholder(tf.bool, shape=[num_rows, max_input_len])\n",
    "\n",
    "gru_cell = tf.contrib.rnn.GRUCell(hidden_layer_size)\n",
    "\n",
    "## Question module\n",
    "with tf.variable_scope('question_module'):\n",
    "    _, q = tf.nn.dynamic_rnn(gru_cell,\n",
    "                                  questions,\n",
    "                                  dtype=tf.float32)\n",
    "    \n",
    "## Input module\n",
    "with tf.variable_scope('input_module'):\n",
    "    i_output, _ = tf.nn.dynamic_rnn(gru_cell,\n",
    "                                          inputs,\n",
    "                                          dtype=tf.float32,\n",
    "                                          sequence_length=input_sequence_lengths)\n",
    "c = []\n",
    "for index in range(num_rows):\n",
    "    states_at_periods = tf.boolean_mask(i_output[index,:,:], periods[index,:])\n",
    "    padding = tf.zeros([max_facts - tf.shape(states_at_periods)[0], hidden_layer_size])\n",
    "    c.append(tf.concat([states_at_periods, padding], 0))\n",
    "c = tf.unstack(tf.transpose(tf.stack(c), perm=[1,0,2]), num = max_facts)\n",
    "c_stacked = tf.transpose(tf.stack(c), perm = [1, 0, 2])\n",
    "\n",
    "## Episodic Memory module\n",
    "with tf.variable_scope('episodic_memory_module_3') as scope:\n",
    "    m_i = q\n",
    "    m_i_2 = q\n",
    "    for step in range(num_steps):\n",
    "#         h_t = tf.zeros_like(c[0])\n",
    "        e_i = tf.zeros_like(c[0])\n",
    "        g = []\n",
    "        for c_t in c:\n",
    "            # calculate g\n",
    "            z = tf.concat([tf.multiply(c_t, q), \n",
    "                           tf.multiply(c_t, m_i),\n",
    "                           tf.abs(tf.subtract(c_t, q)),\n",
    "                           tf.abs(tf.subtract(c_t, m_i))], 1)\n",
    "            layer1 = tf.contrib.layers.fully_connected(inputs = z,\n",
    "                                                      num_outputs = hidden_layer_size,\n",
    "                                                      activation_fn = tf.nn.tanh,\n",
    "                                                      reuse = True,\n",
    "                                                      scope = 'g_layer_1')\n",
    "            g_t = tf.contrib.layers.fully_connected(inputs = layer1,\n",
    "                                                      num_outputs = 1,\n",
    "                                                      activation_fn = tf.nn.sigmoid,\n",
    "                                                      reuse = True,\n",
    "                                                      scope = 'g_layer_2')\n",
    "            g.append(g_t)\n",
    "        g = tf.transpose(tf.stack(g), perm = [1, 0, 2])\n",
    "        g_softmax = tf.nn.softmax(g, dim = 1)\n",
    "        e_i = tf.reduce_sum(tf.multiply(g_softmax, c_stacked), axis = 1)\n",
    "\n",
    "#             # compute episode for pass i\n",
    "#             h_t = tf.multiply(g, gru_cell(c_t, h_t)[1]) + tf.multiply(1 - g, h_t)\n",
    "#             scope.reuse_variables()\n",
    "#         # episode is the last hidden state\n",
    "#         e_i = h_t\n",
    "\n",
    "        m_i = gru_cell(e_i, m_i)[1]\n",
    "        scope.reuse_variables()\n",
    "        \n",
    "## Answer module\n",
    "with tf.variable_scope('answer_module_1') as scope:\n",
    "    logits = tf.contrib.layers.fully_connected(inputs = m_i,\n",
    "                                              num_outputs = vocab_size,\n",
    "                                              activation_fn = None)\n",
    "    \n",
    "    ## Loss and metrics\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = answers)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "    scope.reuse_variables()\n",
    "    prediction = tf.cast(tf.argmax(logits, 1), 'int32')\n",
    "    num_correct = tf.reduce_sum(tf.cast(tf.equal(prediction, answers), tf.int32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, answers), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(sess, num_epochs):\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss, _, epoch_num_correct, epoch_accuracy = sess.run((loss, optimizer, num_correct, accuracy), \n",
    "                                                                    feed_dict={inputs: data_inputs, \n",
    "                                                                            questions: data_questions, \n",
    "                                                                            answers: data_answers, \n",
    "                                                                            periods: input_period_boolean})\n",
    "        print(\"Epoch %d: %.2f%% complete, %d mins, Loss: %.9f, Num correct: %d, Accuracy: %.2f%%\" % (epoch, \n",
    "                                                                           epoch/num_epochs*100,\n",
    "                                                                            (time.time() - start_time)/60,\n",
    "                                                                           epoch_loss, \n",
    "                                                                           epoch_num_correct,\n",
    "                                                                            epoch_accuracy*100))\n",
    "    end_time = time.time()\n",
    "    print(\"Duration: %d mins\" % int((end_time - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.00% complete, 3 mins, Loss: 12.902564049, Num correct: 0, Accuracy: 0.00%\n",
      "Epoch 1: 2.00% complete, 5 mins, Loss: 12.884152412, Num correct: 172, Accuracy: 17.20%\n",
      "Epoch 2: 4.00% complete, 7 mins, Loss: 12.862736702, Num correct: 178, Accuracy: 17.80%\n",
      "Epoch 3: 6.00% complete, 9 mins, Loss: 12.832733154, Num correct: 184, Accuracy: 18.40%\n",
      "Epoch 4: 8.00% complete, 12 mins, Loss: 12.790879250, Num correct: 170, Accuracy: 17.00%\n",
      "Epoch 5: 10.00% complete, 14 mins, Loss: 12.734355927, Num correct: 173, Accuracy: 17.30%\n",
      "Epoch 6: 12.00% complete, 16 mins, Loss: 12.660707474, Num correct: 178, Accuracy: 17.80%\n",
      "Epoch 7: 14.00% complete, 18 mins, Loss: 12.568312645, Num correct: 181, Accuracy: 18.10%\n",
      "Epoch 8: 16.00% complete, 20 mins, Loss: 12.455598831, Num correct: 171, Accuracy: 17.10%\n",
      "Epoch 9: 18.00% complete, 395 mins, Loss: 12.319650650, Num correct: 176, Accuracy: 17.60%\n",
      "Epoch 10: 20.00% complete, 398 mins, Loss: 12.157883644, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 11: 22.00% complete, 400 mins, Loss: 11.969871521, Num correct: 186, Accuracy: 18.60%\n",
      "Epoch 12: 24.00% complete, 402 mins, Loss: 11.758125305, Num correct: 186, Accuracy: 18.60%\n",
      "Epoch 13: 26.00% complete, 405 mins, Loss: 11.527333260, Num correct: 180, Accuracy: 18.00%\n",
      "Epoch 14: 28.00% complete, 408 mins, Loss: 11.282198906, Num correct: 178, Accuracy: 17.80%\n",
      "Epoch 15: 30.00% complete, 411 mins, Loss: 11.026019096, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 16: 32.00% complete, 413 mins, Loss: 10.761414528, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 17: 34.00% complete, 416 mins, Loss: 10.491154671, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 18: 36.00% complete, 418 mins, Loss: 10.217853546, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 19: 38.00% complete, 421 mins, Loss: 9.943502426, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 20: 40.00% complete, 423 mins, Loss: 9.669455528, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 21: 42.00% complete, 426 mins, Loss: 9.396581650, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 22: 44.00% complete, 429 mins, Loss: 9.125423431, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 23: 46.00% complete, 431 mins, Loss: 8.856331825, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 24: 48.00% complete, 434 mins, Loss: 8.589554787, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 25: 50.00% complete, 436 mins, Loss: 8.325285912, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 26: 52.00% complete, 438 mins, Loss: 8.063661575, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 27: 54.00% complete, 441 mins, Loss: 7.804737568, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 28: 56.00% complete, 444 mins, Loss: 7.548485756, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 29: 58.00% complete, 447 mins, Loss: 7.294800758, Num correct: 177, Accuracy: 17.70%\n",
      "Epoch 30: 60.00% complete, 449 mins, Loss: 7.043515205, Num correct: 177, Accuracy: 17.70%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-18025c71599f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-84c4f6caa033>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(sess, num_epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                             \u001b[0mquestions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata_questions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                             \u001b[0manswers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata_answers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                                                             periods: input_period_boolean})\n\u001b[0m\u001b[1;32m      9\u001b[0m         print(\"Epoch %d: %.2f%% complete, %d mins, Loss: %.9f, Num correct: %d, Accuracy: %.2f%%\" % (epoch, \n\u001b[1;32m     10\u001b[0m                                                                            \u001b[0mepoch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amolmane/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amolmane/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amolmane/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/amolmane/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amolmane/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_model(sess, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_model(sess, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = read_data(\"../../datasets/facebook_babi/tasks_1-20_v1-2/en/qa1_single-supporting-fact_test.txt\")\n",
    "max_input_len = max_len(data, 'I')\n",
    "max_question_len = max_len(data, 'Q')\n",
    "max_answer_len = max_len(data, 'A')\n",
    "data_inputs, data_questions = embed_and_pad(data)\n",
    "data_answers = get_answer_index(data)\n",
    "input_sequence_lengths = get_input_sequence_lengths(data)\n",
    "input_period_boolean = get_input_period_boolean(data)\n",
    "max_facts = get_max_facts(input_period_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_prediction, test_num_correct, test_accuracy = sess.run((loss, prediction, num_correct, accuracy), feed_dict={inputs: data_inputs, \n",
    "                                                        questions: data_questions, \n",
    "                                                        answers: data_answers, \n",
    "                                                        periods: input_period_boolean})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
