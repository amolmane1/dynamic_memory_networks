{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 400000\n",
    "embedding_dim = 50\n",
    "hidden_layer_size = 80\n",
    "num_rows = 1000\n",
    "num_steps = 3\n",
    "batch_size = 100\n",
    "num_batches = num_rows/batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_glove(filename):\n",
    "    file = open(filename)    \n",
    "    embedding = np.ndarray([vocab_size, embedding_dim])\n",
    "    word_id_dict = {}\n",
    "    id_word_dict = {}\n",
    "    id = 0\n",
    "    for line in file:\n",
    "        items = line.split(' ')\n",
    "        word_id_dict[items[0]] = id\n",
    "        id_word_dict[id] = items[0]\n",
    "        embedding[id,:] = np.array([float(i) for i in items[1:]])\n",
    "        id += 1\n",
    "    file.close()\n",
    "    return(embedding, word_id_dict, id_word_dict)\n",
    "\n",
    "embedding, word_id_dict, id_word_dict = read_glove(\"../../../datasets/glove_6b/glove.6B.50d.txt\")\n",
    "\n",
    "def read_data(filename):\n",
    "    file = open(filename)\n",
    "    chapter_input = []\n",
    "    data = []\n",
    "    for line in file:\n",
    "        items = re.sub('[?.]', '', line).lower().split()\n",
    "        if items[0] == '1':\n",
    "            chapter_input = items[1:] + ['.']\n",
    "        elif items[-1].isdigit():\n",
    "            data.append({'I': chapter_input,\n",
    "                         'Q': items[1:-2],\n",
    "                         'A': [items[-2]]})\n",
    "        else:\n",
    "            chapter_input = chapter_input + items[1:] + ['.']\n",
    "    file.close()\n",
    "    return(data)\n",
    "\n",
    "def max_len(data, iqa):\n",
    "    max_len = 0\n",
    "    for i in data:\n",
    "        max_len = max(max_len, len(i[iqa]))\n",
    "    return(max_len)\n",
    "\n",
    "def embed_and_pad(data):\n",
    "    inputs = np.zeros([len(data), max_len(data, 'I'), embedding_dim])\n",
    "    questions = np.zeros([len(data), max_len(data, 'Q'), embedding_dim])\n",
    "    for index, row in enumerate(data):\n",
    "        inputs[index,0:len(row['I']),:] = embedding[[word_id_dict[token] for token in row['I']]]\n",
    "        questions[index,0:len(row['Q']),:] = embedding[[word_id_dict[token] for token in row['Q']]]\n",
    "    return((inputs, questions))\n",
    "\n",
    "def get_answer_index(data):\n",
    "    answers = np.zeros(num_rows)\n",
    "    for index, row in enumerate(data):\n",
    "        answers[index] = word_id_dict[row['A'][0]]\n",
    "    return(answers)\n",
    "\n",
    "def get_input_sequence_lengths(data):\n",
    "    input_sequence_lengths = []\n",
    "    for i in data:\n",
    "        input_sequence_lengths.append(len(i['I']))\n",
    "    return(input_sequence_lengths)\n",
    "\n",
    "def get_input_period_boolean(data):\n",
    "    input_period_boolean = np.zeros((num_rows, max_input_len), dtype=bool)\n",
    "    for index, row in enumerate(data):\n",
    "        input_period_boolean[index, [i for i, j in enumerate(row['I']) if j=='.']] = True\n",
    "    return(input_period_boolean)\n",
    "\n",
    "def get_max_facts(input_period_boolean):\n",
    "    max_facts = max([sum(i) for i in input_period_boolean])\n",
    "    return(max_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = read_data(\"../../../datasets/facebook_babi/tasks_1-20_v1-2/en/qa1_single-supporting-fact_train.txt\")\n",
    "max_input_len = max_len(data, 'I')\n",
    "max_question_len = max_len(data, 'Q')\n",
    "max_answer_len = max_len(data, 'A')\n",
    "data_inputs, data_questions = embed_and_pad(data)\n",
    "data_answers = get_answer_index(data)\n",
    "input_sequence_lengths = get_input_sequence_lengths(data)\n",
    "input_period_boolean = get_input_period_boolean(data)\n",
    "max_facts = get_max_facts(input_period_boolean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Placeholders\n",
    "inputs = tf.placeholder(tf.float32, shape=[batch_size, max_input_len, embedding_dim])\n",
    "questions = tf.placeholder(tf.float32, shape=[batch_size, max_question_len, embedding_dim])\n",
    "answers = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "periods = tf.placeholder(tf.bool, shape=[batch_size, max_input_len])\n",
    "input_sequence_lengths_placeholder = tf.placeholder(tf.int32, shape=[batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.variable_scope('trial7') as scope:\n",
    "# #     gru_cell_2 = tf.contrib.rnn.GRUCell(hidden_layer_size)\n",
    "#     trial_data = tf.constant(np.random.rand(10, 1000, 320), dtype = tf.float32)\n",
    "    \n",
    "#     w1 = tf.get_variable(\"w1\", [4*hidden_layer_size, hidden_layer_size],\n",
    "#             initializer=tf.random_normal_initializer())\n",
    "# #     layer1 = tf.nn.tanh(tf.matmul(z, w1))\n",
    "# #     scope.reuse_variables()        \n",
    "#     w2 = tf.get_variable(\"weights2\", [hidden_layer_size, hidden_layer_size],\n",
    "#             initializer=tf.random_normal_initializer())\n",
    "# #     g_t = tf.nn.sigmoid(tf.matmul(layer1, w2))\n",
    "    \n",
    "#     for i in range(3):\n",
    "#         for j in range(10):\n",
    "#             inp = trial_data[j, :, :]\n",
    "#             layer1 = tf.nn.tanh(tf.matmul(inp, w1))\n",
    "#             g_t = tf.nn.sigmoid(tf.matmul(layer1, w2))\n",
    "# #     m = q\n",
    "# #     for i in range(10):\n",
    "# #         inp = trial_data[0, :, :]\n",
    "# #         m = gru_cell_2(inp, m)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# with tf.variable_scope('trial5') as scope:\n",
    "#     gru_cell_2 = tf.contrib.rnn.GRUCell(hidden_layer_size)\n",
    "#     trial_data = tf.constant(np.random.rand(10, 1000, 80), dtype = tf.float32)\n",
    "#     m = q\n",
    "#     for i in range(10):\n",
    "#         inp = trial_data[0, :, :]\n",
    "#         m = gru_cell_2(inp, m)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Question module\n",
    "# with tf.variable_scope('question_module_1') as scope:\n",
    "#     _, q = tf.nn.dynamic_rnn(gru_cell,\n",
    "#                                   questions,\n",
    "#                                   dtype=tf.float64)\n",
    "\n",
    "# ## Input module\n",
    "# with tf.variable_scope('input_module_1') as scope:\n",
    "#     i_output, _ = tf.nn.dynamic_rnn(gru_cell,\n",
    "#                                           inputs,\n",
    "#                                           dtype=tf.float32,\n",
    "#                                           sequence_length=input_sequence_lengths)\n",
    "#     c = []\n",
    "#     for index in range(num_rows):\n",
    "#         states_at_periods = tf.boolean_mask(i_output[index,:,:], periods[index,:])\n",
    "#         padding = tf.zeros([max_facts - tf.shape(states_at_periods)[0], hidden_layer_size])\n",
    "#         c.append(tf.concat([states_at_periods, padding], 0))\n",
    "#     c = tf.unstack(tf.transpose(tf.stack(c), perm=[1,0,2]), num = max_facts)\n",
    "#     c_stacked = tf.transpose(tf.stack(c), perm = [1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Question and Input module\n",
    "with tf.variable_scope('question_and_input_module') as scope:\n",
    "    input_gru_cell = tf.contrib.rnn.GRUCell(hidden_layer_size)\n",
    "\n",
    "    _, q = tf.nn.dynamic_rnn(input_gru_cell,\n",
    "                                  questions,\n",
    "                                  dtype=tf.float32)\n",
    "    scope.reuse_variables()\n",
    "\n",
    "    i_output, _ = tf.nn.dynamic_rnn(input_gru_cell,\n",
    "                                          inputs,\n",
    "                                          dtype=tf.float32,\n",
    "                                          sequence_length=input_sequence_lengths_placeholder)\n",
    "    \n",
    "    c = []\n",
    "    for index in range(batch_size):\n",
    "        states_at_periods = tf.boolean_mask(i_output[index,:,:], periods[index,:])\n",
    "        padding = tf.zeros([max_facts - tf.shape(states_at_periods)[0], hidden_layer_size])\n",
    "        c.append(tf.concat([states_at_periods, padding], 0))\n",
    "    c = tf.unstack(tf.transpose(tf.stack(c), perm=[1,0,2]), num = max_facts)\n",
    "    c_stacked = tf.transpose(tf.stack(c), perm = [1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Episodic Memory module\n",
    "with tf.variable_scope('episodic_memory_module'):\n",
    "    episodic_gru_cell = tf.contrib.rnn.GRUCell(hidden_layer_size)\n",
    "    w1 = tf.get_variable(\"weight_1\", [4*hidden_layer_size, hidden_layer_size],\n",
    "                        initializer=tf.random_normal_initializer())\n",
    "    w2 = tf.get_variable(\"weight_2\", [hidden_layer_size, hidden_layer_size],\n",
    "                        initializer=tf.random_normal_initializer())\n",
    "    \n",
    "    m_i = q\n",
    "    for step in range(num_steps):\n",
    "#         h_t = tf.zeros_like(c[0])\n",
    "        e_i = tf.zeros_like(c[0])\n",
    "        g = []\n",
    "        for c_t in c:\n",
    "            # calculate g\n",
    "            z = tf.concat([tf.multiply(c_t, q), \n",
    "                           tf.multiply(c_t, m_i),\n",
    "                           tf.abs(tf.subtract(c_t, q)),\n",
    "                           tf.abs(tf.subtract(c_t, m_i))], 1) # [N x 4d]\n",
    "#             with tf.variable_scope(\"layers\", reuse = True) as scope:\n",
    "# #                 w1 = tf.get_variable(\"weights1\", [4*hidden_layer_size, hidden_layer_size],\n",
    "# #                         initializer=tf.random_normal_initializer())\n",
    "#                 layer1 = tf.nn.tanh(tf.matmul(z, w1))\n",
    "#                 scope.reuse_variables()        \n",
    "# #                 w2 = tf.get_variable(\"weights2\", [hidden_layer_size, hidden_layer_size],\n",
    "# #                         initializer=tf.random_normal_initializer())\n",
    "#                 g_t = tf.nn.sigmoid(tf.matmul(layer1, w2))\n",
    "# #                 scope.reuse_variables()\n",
    "# #             layer1 = tf.contrib.layers.fully_connected(inputs = z,\n",
    "# #                                                       num_outputs = hidden_layer_size,\n",
    "# #                                                       activation_fn = tf.nn.tanh,\n",
    "# #                                                       reuse = None,\n",
    "# #                                                       scope = \"layer_1\")\n",
    "# # #             with tf.variable_scope(\"layer_22\"):\n",
    "# #             g_t = tf.contrib.layers.fully_connected(inputs = layer1,\n",
    "# #                                                       num_outputs = 1,\n",
    "# #                                                       activation_fn = tf.nn.sigmoid,\n",
    "# #                                                    reuse = None,\n",
    "# #                                                    scope = \"layer_2\")\n",
    "            layer1 = tf.nn.tanh(tf.matmul(z, w1))\n",
    "            g_t = tf.nn.sigmoid(tf.matmul(layer1, w2))\n",
    "            g.append(g_t)\n",
    "        g = tf.transpose(tf.stack(g), perm = [1, 0, 2])\n",
    "        g_softmax = tf.nn.softmax(g, dim = 1)\n",
    "        e_i = tf.reduce_sum(tf.multiply(g_softmax, c_stacked), axis = 1)\n",
    "\n",
    "#             # compute episode for pass i\n",
    "#             h_t = tf.multiply(g, gru_cell(c_t, h_t)[1]) + tf.multiply(1 - g, h_t)\n",
    "#             scope.reuse_variables()\n",
    "#         # episode is the last hidden state\n",
    "#         e_i = h_t\n",
    "\n",
    "        m_i = episodic_gru_cell(e_i, m_i)[1]\n",
    "#         scope.reuse_variables()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Answer module\n",
    "with tf.variable_scope('answer_module') as scope:\n",
    "    logits = tf.contrib.layers.fully_connected(inputs = m_i,\n",
    "                                              num_outputs = vocab_size,\n",
    "                                              activation_fn = None)\n",
    "    \n",
    "    ## Loss and metrics\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = answers)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "    \n",
    "    prediction = tf.cast(tf.argmax(logits, 1), 'int32')\n",
    "    num_correct = tf.reduce_sum(tf.cast(tf.equal(prediction, answers), tf.int32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, answers), tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_number):\n",
    "    return {inputs: data_inputs[batch_number*batch_size: (batch_number+1)*batch_size],\n",
    "            questions: data_questions[batch_number*batch_size: (batch_number+1)*batch_size],\n",
    "            answers: data_answers[batch_number*batch_size: (batch_number+1)*batch_size],\n",
    "            periods: input_period_boolean[batch_number*batch_size: (batch_number+1)*batch_size],\n",
    "            input_sequence_lengths_placeholder: input_sequence_lengths[batch_number*batch_size: (batch_number+1)*batch_size]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(sess, num_epochs):\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = epoch_num_correct =0\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_loss, _, batch_num_correct, batch_accuracy, res_optimizer = sess.run((loss, optimizer, num_correct, accuracy, optimizer), \n",
    "                                                                        feed_dict=get_batch(batch_idx))\n",
    "            epoch_loss += batch_loss\n",
    "            epoch_num_correct += batch_num_correct\n",
    "#             epoch_accuracy += batch_accuracy\n",
    "        print(\"Epoch %d: %.2f%% complete, %d mins, Loss: %.9f, Num correct: %d\" % (epoch, \n",
    "                                                                               epoch*100/num_epochs,\n",
    "                                                                                (time.time() - start_time)/60,\n",
    "                                                                               epoch_loss, \n",
    "                                                                               epoch_num_correct))\n",
    "    end_time = time.time()\n",
    "    print(\"Duration: %d mins\" % int((end_time - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.00% complete, 0 mins, Loss: 83.210313797, Num correct: 152, Accuracy: 152.00%\n",
      "Epoch 1: 0.00% complete, 0 mins, Loss: 18.377319932, Num correct: 158, Accuracy: 158.00%\n",
      "Epoch 2: 0.00% complete, 0 mins, Loss: 18.358591676, Num correct: 142, Accuracy: 142.00%\n",
      "Epoch 3: 0.00% complete, 0 mins, Loss: 18.104773045, Num correct: 133, Accuracy: 133.00%\n",
      "Epoch 4: 0.00% complete, 0 mins, Loss: 18.138466835, Num correct: 141, Accuracy: 141.00%\n",
      "Epoch 5: 0.00% complete, 0 mins, Loss: 18.227027893, Num correct: 145, Accuracy: 145.00%\n",
      "Epoch 6: 0.00% complete, 0 mins, Loss: 18.191586494, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 7: 0.00% complete, 0 mins, Loss: 18.203004122, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 8: 0.00% complete, 0 mins, Loss: 18.227482438, Num correct: 145, Accuracy: 145.00%\n",
      "Epoch 9: 0.00% complete, 0 mins, Loss: 18.230713606, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 10: 0.00% complete, 0 mins, Loss: 18.236656547, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 11: 0.00% complete, 0 mins, Loss: 18.243286729, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 12: 0.00% complete, 0 mins, Loss: 18.247909307, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 13: 0.00% complete, 0 mins, Loss: 18.252863169, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 14: 0.00% complete, 0 mins, Loss: 18.256379604, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 15: 0.00% complete, 0 mins, Loss: 18.258986592, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 16: 0.00% complete, 0 mins, Loss: 18.261907458, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 17: 0.00% complete, 0 mins, Loss: 18.264410973, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 18: 0.00% complete, 0 mins, Loss: 18.266320229, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 19: 0.00% complete, 0 mins, Loss: 18.268107891, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 20: 0.00% complete, 0 mins, Loss: 18.269756794, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 21: 0.00% complete, 0 mins, Loss: 18.271162868, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 22: 0.00% complete, 0 mins, Loss: 18.272403598, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 23: 0.00% complete, 0 mins, Loss: 18.273530722, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 24: 0.00% complete, 0 mins, Loss: 18.274538040, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 25: 0.00% complete, 0 mins, Loss: 18.275440693, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 26: 0.00% complete, 0 mins, Loss: 18.276257157, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 27: 0.00% complete, 0 mins, Loss: 18.276996136, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 28: 0.00% complete, 0 mins, Loss: 18.277667761, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 29: 0.00% complete, 0 mins, Loss: 18.278278351, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 30: 0.00% complete, 0 mins, Loss: 18.278833628, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 31: 0.00% complete, 0 mins, Loss: 18.279342651, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 32: 0.00% complete, 0 mins, Loss: 18.279813409, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 33: 0.00% complete, 0 mins, Loss: 18.280241132, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 34: 0.00% complete, 0 mins, Loss: 18.280634999, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 35: 0.00% complete, 0 mins, Loss: 18.281001210, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 36: 0.00% complete, 0 mins, Loss: 18.281338811, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 37: 0.00% complete, 0 mins, Loss: 18.281652927, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 38: 0.00% complete, 0 mins, Loss: 18.281942844, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 39: 0.00% complete, 0 mins, Loss: 18.282213330, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 40: 0.00% complete, 0 mins, Loss: 18.282465458, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 41: 0.00% complete, 0 mins, Loss: 18.282702923, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 42: 0.00% complete, 0 mins, Loss: 18.282920599, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 43: 0.00% complete, 0 mins, Loss: 18.283125401, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 44: 0.00% complete, 0 mins, Loss: 18.283312201, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 45: 0.00% complete, 0 mins, Loss: 18.283497095, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 46: 0.00% complete, 0 mins, Loss: 18.283668995, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 47: 0.00% complete, 0 mins, Loss: 18.283825994, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 48: 0.00% complete, 0 mins, Loss: 18.283975005, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 49: 0.00% complete, 0 mins, Loss: 18.284123659, Num correct: 144, Accuracy: 144.00%\n",
      "Duration: 0 mins\n"
     ]
    }
   ],
   "source": [
    "run_model(sess, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.00% complete, 0 mins, Loss: 18.284256458, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 1: 0.00% complete, 0 mins, Loss: 18.284379840, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 2: 0.00% complete, 0 mins, Loss: 18.284500837, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 3: 0.00% complete, 0 mins, Loss: 18.284611702, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 4: 0.00% complete, 0 mins, Loss: 18.284720302, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 5: 0.00% complete, 0 mins, Loss: 18.284821749, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 6: 0.00% complete, 0 mins, Loss: 18.284917235, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 7: 0.00% complete, 0 mins, Loss: 18.285007954, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 8: 0.00% complete, 0 mins, Loss: 18.285097480, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 9: 0.00% complete, 0 mins, Loss: 18.285177469, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 10: 0.00% complete, 0 mins, Loss: 18.285256028, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 11: 0.00% complete, 0 mins, Loss: 18.285336256, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 12: 0.00% complete, 0 mins, Loss: 18.285403848, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 13: 0.00% complete, 0 mins, Loss: 18.285475731, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 14: 0.00% complete, 0 mins, Loss: 18.285539746, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 15: 0.00% complete, 0 mins, Loss: 18.285602450, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 16: 0.00% complete, 0 mins, Loss: 18.285660386, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 17: 0.00% complete, 0 mins, Loss: 18.285717010, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 18: 0.00% complete, 0 mins, Loss: 18.285771728, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 19: 0.00% complete, 0 mins, Loss: 18.285822153, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 20: 0.00% complete, 0 mins, Loss: 18.285874486, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 21: 0.00% complete, 0 mins, Loss: 18.285923123, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 22: 0.00% complete, 0 mins, Loss: 18.285969615, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 23: 0.00% complete, 0 mins, Loss: 18.286013365, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 24: 0.00% complete, 0 mins, Loss: 18.286054611, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 25: 0.00% complete, 0 mins, Loss: 18.286094904, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 26: 0.00% complete, 0 mins, Loss: 18.286134601, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 27: 0.00% complete, 0 mins, Loss: 18.286174655, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 28: 0.00% complete, 0 mins, Loss: 18.286209226, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 29: 0.00% complete, 0 mins, Loss: 18.286242962, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 30: 0.00% complete, 0 mins, Loss: 18.286281466, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 31: 0.00% complete, 0 mins, Loss: 18.286312342, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 32: 0.00% complete, 0 mins, Loss: 18.286344767, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 33: 0.00% complete, 0 mins, Loss: 18.286371946, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 34: 0.00% complete, 0 mins, Loss: 18.286399722, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 35: 0.00% complete, 0 mins, Loss: 18.286431909, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 36: 0.00% complete, 0 mins, Loss: 18.286457777, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 37: 0.00% complete, 0 mins, Loss: 18.286481261, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 38: 0.00% complete, 0 mins, Loss: 18.286508679, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 39: 0.00% complete, 0 mins, Loss: 18.286535740, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 40: 0.00% complete, 0 mins, Loss: 18.286555171, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 41: 0.00% complete, 0 mins, Loss: 18.286579013, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 42: 0.00% complete, 0 mins, Loss: 18.286599398, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 43: 0.00% complete, 0 mins, Loss: 18.286623836, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 44: 0.00% complete, 0 mins, Loss: 18.286642790, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 45: 0.00% complete, 0 mins, Loss: 18.286662817, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 46: 0.00% complete, 0 mins, Loss: 18.286678791, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 47: 0.00% complete, 0 mins, Loss: 18.286700249, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 48: 0.00% complete, 0 mins, Loss: 18.286719203, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 49: 0.00% complete, 0 mins, Loss: 18.286739349, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 50: 0.00% complete, 0 mins, Loss: 18.286754847, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 51: 0.00% complete, 0 mins, Loss: 18.286771774, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 52: 0.00% complete, 0 mins, Loss: 18.286788106, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 53: 0.00% complete, 0 mins, Loss: 18.286800623, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 54: 0.00% complete, 1 mins, Loss: 18.286816359, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 55: 0.00% complete, 1 mins, Loss: 18.286830783, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 56: 0.00% complete, 1 mins, Loss: 18.286845565, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 57: 0.00% complete, 1 mins, Loss: 18.286860228, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 58: 0.00% complete, 1 mins, Loss: 18.286868811, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 59: 0.00% complete, 1 mins, Loss: 18.286887765, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 60: 0.00% complete, 1 mins, Loss: 18.286897421, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 61: 0.00% complete, 1 mins, Loss: 18.286910653, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 62: 0.00% complete, 1 mins, Loss: 18.286922336, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 63: 0.00% complete, 1 mins, Loss: 18.286933422, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 64: 0.00% complete, 1 mins, Loss: 18.286945105, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 65: 0.00% complete, 1 mins, Loss: 18.286955357, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 66: 0.00% complete, 1 mins, Loss: 18.286965847, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 67: 0.00% complete, 1 mins, Loss: 18.286976457, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 68: 0.00% complete, 1 mins, Loss: 18.286987543, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 69: 0.00% complete, 1 mins, Loss: 18.286994815, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 70: 0.00% complete, 1 mins, Loss: 18.287004113, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 71: 0.00% complete, 1 mins, Loss: 18.287012935, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 72: 0.00% complete, 1 mins, Loss: 18.287024140, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 73: 0.00% complete, 1 mins, Loss: 18.287031889, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 74: 0.00% complete, 1 mins, Loss: 18.287041306, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 75: 0.00% complete, 1 mins, Loss: 18.287049651, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 76: 0.00% complete, 1 mins, Loss: 18.287056446, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 77: 0.00% complete, 1 mins, Loss: 18.287064910, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 78: 0.00% complete, 1 mins, Loss: 18.287075639, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 79: 0.00% complete, 1 mins, Loss: 18.287080407, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 80: 0.00% complete, 1 mins, Loss: 18.287086606, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 81: 0.00% complete, 1 mins, Loss: 18.287097454, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 82: 0.00% complete, 1 mins, Loss: 18.287102103, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 83: 0.00% complete, 1 mins, Loss: 18.287109375, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 84: 0.00% complete, 1 mins, Loss: 18.287117481, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 85: 0.00% complete, 1 mins, Loss: 18.287121058, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 86: 0.00% complete, 1 mins, Loss: 18.287127733, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 87: 0.00% complete, 1 mins, Loss: 18.287136197, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 88: 0.00% complete, 1 mins, Loss: 18.287138700, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 89: 0.00% complete, 1 mins, Loss: 18.287144661, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 90: 0.00% complete, 1 mins, Loss: 18.287150025, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 91: 0.00% complete, 1 mins, Loss: 18.287157416, Num correct: 144, Accuracy: 144.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: 0.00% complete, 1 mins, Loss: 18.287165642, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 93: 0.00% complete, 1 mins, Loss: 18.287169099, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 94: 0.00% complete, 1 mins, Loss: 18.287173867, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 95: 0.00% complete, 1 mins, Loss: 18.287177563, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 96: 0.00% complete, 1 mins, Loss: 18.287181616, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 97: 0.00% complete, 1 mins, Loss: 18.287186623, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 98: 0.00% complete, 1 mins, Loss: 18.287192702, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 99: 0.00% complete, 1 mins, Loss: 18.287196875, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 100: 0.00% complete, 1 mins, Loss: 18.287204146, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 101: 0.00% complete, 1 mins, Loss: 18.287206054, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 102: 0.00% complete, 1 mins, Loss: 18.287210464, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 103: 0.00% complete, 1 mins, Loss: 18.287214756, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 104: 0.00% complete, 1 mins, Loss: 18.287218094, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 105: 0.00% complete, 1 mins, Loss: 18.287224650, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 106: 0.00% complete, 2 mins, Loss: 18.287227631, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 107: 0.00% complete, 2 mins, Loss: 18.287229061, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 108: 0.00% complete, 2 mins, Loss: 18.287235141, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 109: 0.00% complete, 2 mins, Loss: 18.287239313, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 110: 0.00% complete, 2 mins, Loss: 18.287242293, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 111: 0.00% complete, 2 mins, Loss: 18.287245035, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 112: 0.00% complete, 2 mins, Loss: 18.287247419, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 113: 0.00% complete, 2 mins, Loss: 18.287252188, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 114: 0.00% complete, 2 mins, Loss: 18.287255287, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 115: 0.00% complete, 2 mins, Loss: 18.287257791, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 116: 0.00% complete, 2 mins, Loss: 18.287264109, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 117: 0.00% complete, 2 mins, Loss: 18.287266254, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 118: 0.00% complete, 2 mins, Loss: 18.287270904, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 119: 0.00% complete, 2 mins, Loss: 18.287272692, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 120: 0.00% complete, 2 mins, Loss: 18.287272692, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 121: 0.00% complete, 2 mins, Loss: 18.287275672, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 122: 0.00% complete, 2 mins, Loss: 18.287279010, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 123: 0.00% complete, 2 mins, Loss: 18.287285089, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 124: 0.00% complete, 2 mins, Loss: 18.287287712, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 125: 0.00% complete, 2 mins, Loss: 18.287290573, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 126: 0.00% complete, 2 mins, Loss: 18.287288785, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 127: 0.00% complete, 2 mins, Loss: 18.287290335, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 128: 0.00% complete, 2 mins, Loss: 18.287292719, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 129: 0.00% complete, 2 mins, Loss: 18.287294388, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 130: 0.00% complete, 2 mins, Loss: 18.287301660, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 131: 0.00% complete, 2 mins, Loss: 18.287306309, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 132: 0.00% complete, 2 mins, Loss: 18.287309527, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 133: 0.00% complete, 2 mins, Loss: 18.287310362, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 134: 0.00% complete, 2 mins, Loss: 18.287308812, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 135: 0.00% complete, 2 mins, Loss: 18.287307024, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 136: 0.00% complete, 2 mins, Loss: 18.287310958, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 137: 0.00% complete, 2 mins, Loss: 18.287313342, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 138: 0.00% complete, 2 mins, Loss: 18.287315488, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 139: 0.00% complete, 2 mins, Loss: 18.287317753, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 140: 0.00% complete, 2 mins, Loss: 18.287320256, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 141: 0.00% complete, 2 mins, Loss: 18.287323236, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 142: 0.00% complete, 2 mins, Loss: 18.287326694, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 143: 0.00% complete, 2 mins, Loss: 18.287329674, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 144: 0.00% complete, 2 mins, Loss: 18.287328362, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 145: 0.00% complete, 2 mins, Loss: 18.287331104, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 146: 0.00% complete, 2 mins, Loss: 18.287332416, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 147: 0.00% complete, 2 mins, Loss: 18.287331581, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 148: 0.00% complete, 2 mins, Loss: 18.287335515, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 149: 0.00% complete, 2 mins, Loss: 18.287333727, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 150: 0.00% complete, 2 mins, Loss: 18.287338495, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 151: 0.00% complete, 2 mins, Loss: 18.287339687, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 152: 0.00% complete, 2 mins, Loss: 18.287339211, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 153: 0.00% complete, 2 mins, Loss: 18.287342072, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 154: 0.00% complete, 2 mins, Loss: 18.287345529, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 155: 0.00% complete, 2 mins, Loss: 18.287349224, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 156: 0.00% complete, 2 mins, Loss: 18.287348509, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 157: 0.00% complete, 2 mins, Loss: 18.287349582, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 158: 0.00% complete, 2 mins, Loss: 18.287350893, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 159: 0.00% complete, 2 mins, Loss: 18.287353277, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 160: 0.00% complete, 2 mins, Loss: 18.287354827, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 161: 0.00% complete, 3 mins, Loss: 18.287353873, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 162: 0.00% complete, 3 mins, Loss: 18.287356973, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 163: 0.00% complete, 3 mins, Loss: 18.287356615, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 164: 0.00% complete, 3 mins, Loss: 18.287357092, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 165: 0.00% complete, 3 mins, Loss: 18.287359953, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 166: 0.00% complete, 3 mins, Loss: 18.287360668, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 167: 0.00% complete, 3 mins, Loss: 18.287362099, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 168: 0.00% complete, 3 mins, Loss: 18.287362933, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 169: 0.00% complete, 3 mins, Loss: 18.287363172, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 170: 0.00% complete, 3 mins, Loss: 18.287364602, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 171: 0.00% complete, 3 mins, Loss: 18.287364960, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 172: 0.00% complete, 3 mins, Loss: 18.287363887, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 173: 0.00% complete, 3 mins, Loss: 18.287366986, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 174: 0.00% complete, 3 mins, Loss: 18.287369251, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 175: 0.00% complete, 3 mins, Loss: 18.287368774, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 176: 0.00% complete, 3 mins, Loss: 18.287370563, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 177: 0.00% complete, 3 mins, Loss: 18.287372470, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 178: 0.00% complete, 3 mins, Loss: 18.287372708, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 179: 0.00% complete, 3 mins, Loss: 18.287373900, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 180: 0.00% complete, 3 mins, Loss: 18.287375212, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 181: 0.00% complete, 3 mins, Loss: 18.287376165, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 182: 0.00% complete, 3 mins, Loss: 18.287376642, Num correct: 144, Accuracy: 144.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183: 0.00% complete, 3 mins, Loss: 18.287377000, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 184: 0.00% complete, 3 mins, Loss: 18.287377715, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 185: 0.00% complete, 3 mins, Loss: 18.287379622, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 186: 0.00% complete, 3 mins, Loss: 18.287380815, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 187: 0.00% complete, 3 mins, Loss: 18.287381291, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 188: 0.00% complete, 3 mins, Loss: 18.287384033, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 189: 0.00% complete, 3 mins, Loss: 18.287383914, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 190: 0.00% complete, 3 mins, Loss: 18.287384987, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 191: 0.00% complete, 3 mins, Loss: 18.287384033, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 192: 0.00% complete, 3 mins, Loss: 18.287385225, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 193: 0.00% complete, 3 mins, Loss: 18.287386656, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 194: 0.00% complete, 3 mins, Loss: 18.287385702, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 195: 0.00% complete, 3 mins, Loss: 18.287385106, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 196: 0.00% complete, 3 mins, Loss: 18.287387967, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 197: 0.00% complete, 3 mins, Loss: 18.287388444, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 198: 0.00% complete, 3 mins, Loss: 18.287387848, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 199: 0.00% complete, 3 mins, Loss: 18.287388444, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 200: 0.00% complete, 3 mins, Loss: 18.287390232, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 201: 0.00% complete, 3 mins, Loss: 18.287391305, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 202: 0.00% complete, 3 mins, Loss: 18.287392139, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 203: 0.00% complete, 3 mins, Loss: 18.287393928, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 204: 0.00% complete, 3 mins, Loss: 18.287394524, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 205: 0.00% complete, 3 mins, Loss: 18.287393689, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 206: 0.00% complete, 3 mins, Loss: 18.287395000, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 207: 0.00% complete, 3 mins, Loss: 18.287395000, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 208: 0.00% complete, 3 mins, Loss: 18.287393689, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 209: 0.00% complete, 3 mins, Loss: 18.287394166, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 210: 0.00% complete, 3 mins, Loss: 18.287395239, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 211: 0.00% complete, 3 mins, Loss: 18.287393689, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 212: 0.00% complete, 3 mins, Loss: 18.287393928, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 213: 0.00% complete, 3 mins, Loss: 18.287397742, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 214: 0.00% complete, 3 mins, Loss: 18.287398219, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 215: 0.00% complete, 3 mins, Loss: 18.287399411, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 216: 0.00% complete, 4 mins, Loss: 18.287400126, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 217: 0.00% complete, 4 mins, Loss: 18.287398577, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 218: 0.00% complete, 4 mins, Loss: 18.287398934, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 219: 0.00% complete, 4 mins, Loss: 18.287398338, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 220: 0.00% complete, 4 mins, Loss: 18.287398696, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 221: 0.00% complete, 4 mins, Loss: 18.287400365, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 222: 0.00% complete, 4 mins, Loss: 18.287399650, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 223: 0.00% complete, 4 mins, Loss: 18.287400603, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 224: 0.00% complete, 4 mins, Loss: 18.287402272, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 225: 0.00% complete, 4 mins, Loss: 18.287402153, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 226: 0.00% complete, 4 mins, Loss: 18.287402153, Num correct: 144, Accuracy: 144.00%\n",
      "Epoch 227: 0.00% complete, 4 mins, Loss: 18.287402153, Num correct: 144, Accuracy: 144.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fb866bde130b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-b9e5a9f5c1cd>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(sess, num_epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             batch_loss, _, batch_num_correct, batch_accuracy, res_optimizer = sess.run((loss, optimizer, num_correct, accuracy, optimizer), \n\u001b[0;32m----> 7\u001b[0;31m                                                                         feed_dict=get_batch(batch_idx))\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mepoch_num_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_num_correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amolmane1/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amolmane1/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amolmane1/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amolmane1/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amolmane1/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_model(sess, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637,\n",
       "       2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637,\n",
       "       2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637,\n",
       "       2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637,\n",
       "       2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637,\n",
       "       2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637,\n",
       "       2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637,\n",
       "       2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637,\n",
       "       2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637, 2637,\n",
       "       2637], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_pred = sess.run(prediction, feed_dict=get_batch(9))\n",
    "res_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'garden'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_word_dict[2637]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = read_data(\"../../datasets/facebook_babi/tasks_1-20_v1-2/en/qa1_single-supporting-fact_test.txt\")\n",
    "# max_input_len = max_len(data, 'I')\n",
    "# max_question_len = max_len(data, 'Q')\n",
    "# max_answer_len = max_len(data, 'A')\n",
    "# data_inputs, data_questions = embed_and_pad(data)\n",
    "# data_answers = get_answer_index(data)\n",
    "# input_sequence_lengths = get_input_sequence_lengths(data)\n",
    "# input_period_boolean = get_input_period_boolean(data)\n",
    "# max_facts = get_max_facts(input_period_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_loss, test_prediction, test_num_correct, test_accuracy = sess.run((loss, prediction, num_correct, accuracy), feed_dict={inputs: data_inputs, \n",
    "#                                                         questions: data_questions, \n",
    "#                                                         answers: data_answers, \n",
    "#                                                         periods: input_period_boolean})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
