{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = 400000\n",
    "embedding_dim = 50\n",
    "max_input_len = None\n",
    "max_question_len = None\n",
    "max_answer_len = None\n",
    "input_sequence_lengths = None\n",
    "input_period_boolean = None\n",
    "input_period_indices = None\n",
    "max_facts = None\n",
    "hidden_layer_size = 10\n",
    "num_rows = 1000\n",
    "num_steps = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open(\"../../datasets/glove.6B/glove.6B.50d.txt\")    \n",
    "embedding = np.ndarray([vocab_size, embedding_dim])\n",
    "word_id_dict = {}\n",
    "id = 0\n",
    "for line in file:\n",
    "    items = line.split(' ')\n",
    "    word_id_dict[items[0]] = id\n",
    "    embedding[id,:] = np.array([float(i) for i in items[1:]])\n",
    "    id += 1\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"../../datasets/facebook_babi/tasks_1-20_v1-2/en/qa1_single-supporting-fact_train.txt\")\n",
    "\n",
    "chapter_input = []\n",
    "data = []\n",
    "for line in file:\n",
    "    items = re.sub('[?.]', '', line).lower().split()\n",
    "    if items[0] == '1':\n",
    "        chapter_input = items[1:] + ['.']\n",
    "    elif items[-1].isdigit():\n",
    "        data.append({'I': chapter_input,\n",
    "                     'Q': items[1:-2],\n",
    "                     'A': [items[-2]]})\n",
    "    else:\n",
    "        chapter_input = chapter_input + items[1:] + ['.']\n",
    "file.close()\n",
    "\n",
    "def max_len(data, iqa):\n",
    "    max_len = 0\n",
    "    for i in data:\n",
    "        max_len = max(max_len, len(i[iqa]))\n",
    "    return(max_len)\n",
    "\n",
    "max_input_len = max_len(data, 'I')\n",
    "max_question_len = max_len(data, 'Q')\n",
    "max_answer_len = max_len(data, 'A')\n",
    "\n",
    "input_sequence_lengths = []\n",
    "for i in data:\n",
    "    input_sequence_lengths.append(len(i['I']))\n",
    "    \n",
    "input_period_boolean = np.zeros((num_rows, max_input_len), dtype=bool)\n",
    "for index, row in enumerate(data):\n",
    "    input_period_boolean[index, [i for i, j in enumerate(row['I']) if j=='.']] = True\n",
    "    \n",
    "input_period_indices = []\n",
    "for i in data:\n",
    "    input_period_indices.append([index for index, j in enumerate(i['I']) if j=='.'])\n",
    "    \n",
    "max_facts = max([len(i) for i in input_period_indices])\n",
    "\n",
    "def embed_and_pad(data):\n",
    "    inputs = np.zeros([len(data), max_len(data, 'I'), embedding_dim])\n",
    "    questions = np.zeros([len(data), max_len(data, 'Q'), embedding_dim])\n",
    "#     answers = np.zeros([len(data), max_len(data, 'A'), embedding_dim])\n",
    "    for index, row in enumerate(data):\n",
    "        inputs[index,0:len(row['I']),:] = embedding[[word_id_dict[token] for token in row['I']]]\n",
    "        questions[index,0:len(row['Q']),:] = embedding[[word_id_dict[token] for token in row['Q']]]\n",
    "#         answers[index,0:len(row['A']),:] = embedding[[word_id_dict[token] for token in row['A']]]\n",
    "    return((inputs, questions))\n",
    "\n",
    "data_inputs, data_questions = embed_and_pad(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(data):\n",
    "    answers = np.zeros((num_rows, vocab_size))\n",
    "    for index, row in enumerate(data):\n",
    "        answers[index, word_id_dict[row['A'][0]]] = 1\n",
    "    return(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_index(data):\n",
    "    answers = np.zeros(num_rows)\n",
    "    for index, row in enumerate(data):\n",
    "        answers[index] = word_id_dict[row['A'][0]]\n",
    "    return(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_answers = answer_index(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMN Implementation (God help me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder for inputs\n",
    "inputs = tf.placeholder(tf.float32, shape=[num_rows, max_input_len, embedding_dim])\n",
    "\n",
    "# placeholder for questions\n",
    "questions = tf.placeholder(tf.float32, shape=[num_rows, max_question_len, embedding_dim])\n",
    "\n",
    "# placeholder for answers\n",
    "answers = tf.placeholder(tf.int32, shape=[num_rows])\n",
    "\n",
    "# placeholder for periods in inputs\n",
    "periods = tf.placeholder(tf.bool, shape=[num_rows, max_input_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gru_cell = tf.contrib.rnn.GRUCell(hidden_layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Question module\n",
    "with tf.variable_scope('question_module'):\n",
    "    _, q = tf.nn.dynamic_rnn(gru_cell,\n",
    "                                  questions,\n",
    "                                  dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Input module\n",
    "with tf.variable_scope('input_module'):\n",
    "    i_output, _ = tf.nn.dynamic_rnn(gru_cell,\n",
    "                                          inputs,\n",
    "                                          dtype=tf.float32,\n",
    "                                          sequence_length=input_sequence_lengths)\n",
    "c = []\n",
    "for index in range(num_rows):\n",
    "    states_at_periods = tf.boolean_mask(i_output[index,:,:], periods[index,:])\n",
    "    padding = tf.zeros([max_facts - tf.shape(states_at_periods)[0], hidden_layer_size])\n",
    "    c.append(tf.concat([states_at_periods, padding], 0))\n",
    "c = tf.unstack(tf.transpose(tf.stack(c), perm=[1,0,2]), num = max_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Episodic Memory module\n",
    "with tf.variable_scope('episodic_memory_module') as scope:\n",
    "    m_i = q\n",
    "    for step in range(num_steps):\n",
    "        h_t = tf.zeros_like(c[0])\n",
    "        e_i = tf.zeros_like(c[0])\n",
    "        for c_t in c:\n",
    "            # calculate g\n",
    "            z = tf.concat([c_t, m_i, q, \n",
    "                           tf.multiply(c_t, q), \n",
    "                           tf.multiply(c_t, m_i),\n",
    "                           tf.abs(tf.subtract(c_t, q)),\n",
    "                           tf.abs(tf.subtract(c_t, m_i))], 1) # need to add 2 more terms in there (V2)\n",
    "            layer1 = tf.contrib.layers.fully_connected(inputs = z,\n",
    "                                                      num_outputs = hidden_layer_size,\n",
    "                                                      activation_fn = tf.nn.tanh,\n",
    "                                                      reuse = True,\n",
    "                                                      scope = 'g_layer_1')\n",
    "            g = tf.contrib.layers.fully_connected(inputs = layer1,\n",
    "                                                      num_outputs = 1,\n",
    "                                                      activation_fn = tf.nn.sigmoid,\n",
    "                                                      reuse = True,\n",
    "                                                      scope = 'g_layer_2')\n",
    "            # from section 4.1\n",
    "            e_i = tf.add(e_i, tf.multiply(tf.nn.softmax(g), c_t))\n",
    "    #             # compute episode for pass i\n",
    "    #             h_t = tf.multiply(g, gru_cell(c_t, h_t)) + tf.multiply(tf.subtract(1, g), h_t)\n",
    "    #         # episode is the last hidden state\n",
    "    #         e_i = h_t\n",
    "        m_i = gru_cell(e_i, m_i)[0]\n",
    "        scope.reuse_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Answer module\n",
    "with tf.variable_scope('answer_module'):\n",
    "    logits = tf.contrib.layers.fully_connected(inputs = m_i,\n",
    "                                              num_outputs = vocab_size,\n",
    "                                              activation_fn = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = answers)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdadeltaOptimizer(0.002).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.cast(tf.argmax(logits, 1), 'int32')\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, answers), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.00% complete, 2 mins, Loss: 12.898481369, Accuracy: 0.000000000%\n",
      "Epoch 1: 0.40% complete, 3 mins, Loss: 12.898474693, Accuracy: 0.000000000%\n",
      "Epoch 2: 0.80% complete, 4 mins, Loss: 12.898468971, Accuracy: 0.000000000%\n",
      "Epoch 3: 1.20% complete, 4 mins, Loss: 12.898465157, Accuracy: 0.000000000%\n",
      "Epoch 4: 1.60% complete, 5 mins, Loss: 12.898459435, Accuracy: 0.000000000%\n",
      "Epoch 5: 2.00% complete, 6 mins, Loss: 12.898454666, Accuracy: 0.000000000%\n",
      "Epoch 6: 2.40% complete, 6 mins, Loss: 12.898450851, Accuracy: 0.000000000%\n",
      "Epoch 7: 2.80% complete, 7 mins, Loss: 12.898445129, Accuracy: 0.000000000%\n",
      "Epoch 8: 3.20% complete, 8 mins, Loss: 12.898440361, Accuracy: 0.000000000%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss, _, epoch_accuracy = sess.run((loss, optimizer, accuracy), feed_dict={inputs: data_inputs, \n",
    "                                                                        questions: data_questions, \n",
    "                                                                        answers: data_answers, \n",
    "                                                                        periods: input_period_boolean})\n",
    "    print(\"Epoch %d: %.2f%% complete, %d mins, Loss: %.9f, Accuracy: %.9f%%\" % (epoch, \n",
    "                                                                       epoch/num_epochs*100,\n",
    "                                                                        (time.time() - start_time)/60,\n",
    "                                                                       epoch_loss, \n",
    "                                                                       epoch_accuracy))\n",
    "end_time = time.time()\n",
    "print(\"Duration: %.2f s\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
