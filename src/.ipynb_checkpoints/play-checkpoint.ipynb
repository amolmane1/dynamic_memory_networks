{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = 400000\n",
    "embedding_dim = 50\n",
    "hidden_layer_size = 100\n",
    "num_rows = 1000\n",
    "num_steps = 3\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_glove(filename):\n",
    "    file = open(filename)    \n",
    "    embedding = np.ndarray([vocab_size, embedding_dim])\n",
    "    word_id_dict = {}\n",
    "    id = 0\n",
    "    for line in file:\n",
    "        items = line.split(' ')\n",
    "        word_id_dict[items[0]] = id\n",
    "        embedding[id,:] = np.array([float(i) for i in items[1:]])\n",
    "        id += 1\n",
    "    file.close()\n",
    "    return(embedding, word_id_dict)\n",
    "\n",
    "embedding, word_id_dict = read_glove(\"../../datasets/glove.6B/glove.6B.50d.txt\")\n",
    "\n",
    "def read_data(filename):\n",
    "    file = open(filename)\n",
    "    chapter_input = []\n",
    "    data = []\n",
    "    for line in file:\n",
    "        items = re.sub('[?.]', '', line).lower().split()\n",
    "        if items[0] == '1':\n",
    "            chapter_input = items[1:] + ['.']\n",
    "        elif items[-1].isdigit():\n",
    "            data.append({'I': chapter_input,\n",
    "                         'Q': items[1:-2],\n",
    "                         'A': [items[-2]]})\n",
    "        else:\n",
    "            chapter_input = chapter_input + items[1:] + ['.']\n",
    "    file.close()\n",
    "    return(data)\n",
    "\n",
    "def max_len(data, iqa):\n",
    "    max_len = 0\n",
    "    for i in data:\n",
    "        max_len = max(max_len, len(i[iqa]))\n",
    "    return(max_len)\n",
    "\n",
    "def embed_and_pad(data):\n",
    "    inputs = np.zeros([len(data), max_len(data, 'I'), embedding_dim])\n",
    "    questions = np.zeros([len(data), max_len(data, 'Q'), embedding_dim])\n",
    "    for index, row in enumerate(data):\n",
    "        inputs[index,0:len(row['I']),:] = embedding[[word_id_dict[token] for token in row['I']]]\n",
    "        questions[index,0:len(row['Q']),:] = embedding[[word_id_dict[token] for token in row['Q']]]\n",
    "    return((inputs, questions))\n",
    "\n",
    "def get_answer_index(data):\n",
    "    answers = np.zeros(num_rows)\n",
    "    for index, row in enumerate(data):\n",
    "        answers[index] = word_id_dict[row['A'][0]]\n",
    "    return(answers)\n",
    "\n",
    "def get_input_sequence_lengths(data):\n",
    "    input_sequence_lengths = []\n",
    "    for i in data:\n",
    "        input_sequence_lengths.append(len(i['I']))\n",
    "    return(input_sequence_lengths)\n",
    "\n",
    "def get_input_period_boolean(data):\n",
    "    input_period_boolean = np.zeros((num_rows, max_input_len), dtype=bool)\n",
    "    for index, row in enumerate(data):\n",
    "        input_period_boolean[index, [i for i, j in enumerate(row['I']) if j=='.']] = True\n",
    "    return(input_period_boolean)\n",
    "\n",
    "def get_max_facts(input_period_boolean):\n",
    "    max_facts = max([sum(i) for i in input_period_boolean])\n",
    "    return(max_facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-94e12cb2cd9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mstates_at_periods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_facts\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_at_periods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstates_at_periods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_facts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amolmane/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m    895\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mr_binary_op_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amolmane/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    649\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amolmane/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amolmane/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    174\u001b[0m                                          as_ref=False):\n\u001b[1;32m    175\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amolmane/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 165\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    166\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/Users/amolmane/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "## Placeholders\n",
    "inputs = tf.placeholder(tf.float32, shape=[num_rows, max_input_len, embedding_dim])\n",
    "questions = tf.placeholder(tf.float32, shape=[num_rows, max_question_len, embedding_dim])\n",
    "answers = tf.placeholder(tf.int32, shape=[num_rows])\n",
    "periods = tf.placeholder(tf.bool, shape=[num_rows, max_input_len])\n",
    "\n",
    "gru_cell = tf.contrib.rnn.GRUCell(hidden_layer_size)\n",
    "\n",
    "## Question module\n",
    "with tf.variable_scope('question_module'):\n",
    "    _, q = tf.nn.dynamic_rnn(gru_cell,\n",
    "                                  questions,\n",
    "                                  dtype=tf.float32)\n",
    "    \n",
    "## Input module\n",
    "with tf.variable_scope('input_module'):\n",
    "    i_output, _ = tf.nn.dynamic_rnn(gru_cell,\n",
    "                                          inputs,\n",
    "                                          dtype=tf.float32,\n",
    "                                          sequence_length=input_sequence_lengths)\n",
    "c = []\n",
    "for index in range(num_rows):\n",
    "    states_at_periods = tf.boolean_mask(i_output[index,:,:], periods[index,:])\n",
    "    padding = tf.zeros([max_facts - tf.shape(states_at_periods)[0], hidden_layer_size])\n",
    "    c.append(tf.concat([states_at_periods, padding], 0))\n",
    "c = tf.unstack(tf.transpose(tf.stack(c), perm=[1,0,2]), num = max_facts)\n",
    "\n",
    "## Episodic Memory module\n",
    "with tf.variable_scope('episodic_memory_module') as scope:\n",
    "    m_i = q\n",
    "    for step in range(num_steps):\n",
    "        h_t = tf.zeros_like(c[0])\n",
    "        e_i = tf.zeros_like(c[0])\n",
    "        for c_t in c:\n",
    "            # calculate g\n",
    "            z = tf.concat([c_t, m_i, q, \n",
    "                           tf.multiply(c_t, q), \n",
    "                           tf.multiply(c_t, m_i),\n",
    "                           tf.abs(tf.subtract(c_t, q)),\n",
    "                           tf.abs(tf.subtract(c_t, m_i))], 1) # need to add 2 more terms in there (V2)\n",
    "            layer1 = tf.contrib.layers.fully_connected(inputs = z,\n",
    "                                                      num_outputs = hidden_layer_size,\n",
    "                                                      activation_fn = tf.nn.tanh,\n",
    "                                                      reuse = True,\n",
    "                                                      scope = 'g_layer_1')\n",
    "            g = tf.contrib.layers.fully_connected(inputs = layer1,\n",
    "                                                      num_outputs = 1,\n",
    "                                                      activation_fn = tf.nn.sigmoid,\n",
    "                                                      reuse = True,\n",
    "                                                      scope = 'g_layer_2')\n",
    "            # from section 4.1\n",
    "            e_i = tf.add(e_i, tf.multiply(tf.nn.softmax(g), c_t))\n",
    "    #             # compute episode for pass i\n",
    "    #             h_t = tf.multiply(g, gru_cell(c_t, h_t)) + tf.multiply(tf.subtract(1, g), h_t)\n",
    "    #         # episode is the last hidden state\n",
    "    #         e_i = h_t\n",
    "        m_i = gru_cell(e_i, m_i)[0]\n",
    "        scope.reuse_variables()\n",
    "        \n",
    "## Answer module\n",
    "with tf.variable_scope('answer_module'):\n",
    "    logits = tf.contrib.layers.fully_connected(inputs = m_i,\n",
    "                                              num_outputs = vocab_size,\n",
    "                                              activation_fn = None)\n",
    "    \n",
    "## Loss and metrics\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = answers)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "prediction = tf.cast(tf.argmax(logits, 1), 'int32')\n",
    "num_correct = tf.reduce_sum(tf.cast(tf.equal(prediction, answers), tf.int32))\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, answers), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = read_data(\"../../datasets/facebook_babi/tasks_1-20_v1-2/en/qa1_single-supporting-fact_train.txt\")\n",
    "max_input_len = max_len(data, 'I')\n",
    "max_question_len = max_len(data, 'Q')\n",
    "max_answer_len = max_len(data, 'A')\n",
    "data_inputs, data_questions = embed_and_pad(data)\n",
    "data_answers = get_answer_index(data)\n",
    "input_sequence_lengths = get_input_sequence_lengths(data)\n",
    "input_period_boolean = get_input_period_boolean(data)\n",
    "max_facts = get_max_facts(input_period_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.00% complete, 4 mins, Loss: 12.906951904, Num correct: 0, Accuracy: 0.0000\n",
      "Epoch 1: 33.33% complete, 6 mins, Loss: 12.835850716, Num correct: 155, Accuracy: 0.1550\n",
      "Epoch 2: 66.67% complete, 8 mins, Loss: 12.753013611, Num correct: 155, Accuracy: 0.1550\n",
      "Duration: 8 mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss, _, epoch_num_correct, epoch_accuracy = sess.run((loss, optimizer, num_correct, accuracy), \n",
    "                                                                feed_dict={inputs: data_inputs, \n",
    "                                                                        questions: data_questions, \n",
    "                                                                        answers: data_answers, \n",
    "                                                                        periods: input_period_boolean})\n",
    "    print(\"Epoch %d: %.2f%% complete, %d mins, Loss: %.9f, Num correct: %d, Accuracy: %.2f%%\" % (epoch, \n",
    "                                                                       epoch/num_epochs*100,\n",
    "                                                                        (time.time() - start_time)/60,\n",
    "                                                                       epoch_loss, \n",
    "                                                                       epoch_num_correct,\n",
    "                                                                        epoch_accuracy*100))\n",
    "end_time = time.time()\n",
    "print(\"Duration: %d mins\" % int((end_time - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = read_data(\"../../datasets/facebook_babi/tasks_1-20_v1-2/en/qa1_single-supporting-fact_test.txt\")\n",
    "max_input_len = max_len(data, 'I')\n",
    "max_question_len = max_len(data, 'Q')\n",
    "max_answer_len = max_len(data, 'A')\n",
    "data_inputs, data_questions = embed_and_pad(data)\n",
    "data_answers = get_answer_index(data)\n",
    "input_sequence_lengths = get_input_sequence_lengths(data)\n",
    "input_period_boolean = get_input_period_boolean(data)\n",
    "max_facts = get_max_facts(input_period_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prediction = sess.run(prediction, feed_dict={inputs: data_inputs, \n",
    "                                                        questions: data_questions, \n",
    "                                                        answers: data_answers, \n",
    "                                                        periods: input_period_boolean})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
